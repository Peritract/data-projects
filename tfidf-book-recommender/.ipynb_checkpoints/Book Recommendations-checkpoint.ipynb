{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores a dataset of book recommendations, attempting to create a recommendation tool based on similarities between descriptions.\n",
    "\n",
    "The notebook focuses on three questions:\n",
    "\n",
    "1. **What are the most frequent words in descriptions?**\n",
    "\n",
    "    The most frequent words in book descriptions (once stop words have been removed) are those that have the least importance and discriminating power, as they will not distinguish one book from another effectively. Being able to identify these words could help authors and publishers write more useful book descriptions, avoiding words that are essentially filler terms.\n",
    "\n",
    "\n",
    "2. **Can TF-IDF effectively distinguish between separate books based solely on descriptions?**\n",
    "\n",
    "    Book descriptions are often short and may share significant vocabulary, particularly after cleaning and processing text to reduce dimensionality. There's no point in building a recommendation system based upon TF-IDF if the book descriptions, after cleaning, are not sufficiently distinct.\n",
    "\n",
    "\n",
    "3. **Can book descriptions alone be used to make reasonable recommendations?**\n",
    "\n",
    "    Recommendation systems are used in all sorts of customer-facing contexts; being able to recommend products to consumers based on their past behaviour or interests has obvious implications in terms of boosting sales and/or customer engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Dataframes\n",
    "import re  # Regular expressions\n",
    "from langdetect import detect  # Detect the language of text\n",
    "from nltk.tokenize import word_tokenize  # Split text into words\n",
    "from nltk.corpus import stopwords  # Lists of unimportant words\n",
    "from collections import Counter, defaultdict  # Count word frequency & provide more versatile dicts\n",
    "from pandas.core.common import flatten  # Collapse lists of lists\n",
    "from nltk.stem.wordnet import WordNetLemmatizer  # Reduce terms to their root\n",
    "from nltk import pos_tag  # Tag words with parts of speech\n",
    "import seaborn as sns  # Visualisations\n",
    "import matplotlib.pyplot as plt  # Visualisations\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Convert text to TF-IDF representations\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # Check similarities between vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sourcing\n",
    "\n",
    "Data for this project is sourced from a dataset of popular books on [Kaggle](https://www.kaggle.com/meetnaren/goodreads-best-books)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\"book_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration & cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_authors</th>\n",
       "      <th>book_desc</th>\n",
       "      <th>book_edition</th>\n",
       "      <th>book_format</th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>book_pages</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_rating_count</th>\n",
       "      <th>book_review_count</th>\n",
       "      <th>book_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>Winning will make you famous. Losing means cer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78044E+12</td>\n",
       "      <td>374 pages</td>\n",
       "      <td>4.33</td>\n",
       "      <td>5519135</td>\n",
       "      <td>160706</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Young Adult|Fiction|Science Fiction|Dystopia|F...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J.K. Rowling|Mary GrandPré</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>US Edition</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9.78044E+12</td>\n",
       "      <td>870 pages</td>\n",
       "      <td>4.48</td>\n",
       "      <td>2041594</td>\n",
       "      <td>33264</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Fantasy|Young Adult|Fiction</td>\n",
       "      <td>https://images.gr-assets.com/books/1255614970l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>50th Anniversary</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9.78006E+12</td>\n",
       "      <td>324 pages</td>\n",
       "      <td>4.27</td>\n",
       "      <td>3745197</td>\n",
       "      <td>79450</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Classics|Fiction|Historical|Historical Fiction...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen|Anna Quindlen|Mrs. Oliphant|George...</td>\n",
       "      <td>«È cosa ormai risaputa che a uno scapolo in po...</td>\n",
       "      <td>Modern Library Classics, USA / CAN</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9.78068E+12</td>\n",
       "      <td>279 pages</td>\n",
       "      <td>4.25</td>\n",
       "      <td>2453620</td>\n",
       "      <td>54322</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Classics|Fiction|Romance</td>\n",
       "      <td>https://images.gr-assets.com/books/1320399351l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>About three things I was absolutely positive.F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9.78032E+12</td>\n",
       "      <td>498 pages</td>\n",
       "      <td>3.58</td>\n",
       "      <td>4281268</td>\n",
       "      <td>97991</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>Young Adult|Fantasy|Romance|Paranormal|Vampire...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        book_authors  \\\n",
       "0                                    Suzanne Collins   \n",
       "1                         J.K. Rowling|Mary GrandPré   \n",
       "2                                         Harper Lee   \n",
       "3  Jane Austen|Anna Quindlen|Mrs. Oliphant|George...   \n",
       "4                                    Stephenie Meyer   \n",
       "\n",
       "                                           book_desc  \\\n",
       "0  Winning will make you famous. Losing means cer...   \n",
       "1  There is a door at the end of a silent corrido...   \n",
       "2  The unforgettable novel of a childhood in a sl...   \n",
       "3  «È cosa ormai risaputa che a uno scapolo in po...   \n",
       "4  About three things I was absolutely positive.F...   \n",
       "\n",
       "                         book_edition book_format    book_isbn book_pages  \\\n",
       "0                                 NaN   Hardcover  9.78044E+12  374 pages   \n",
       "1                          US Edition   Paperback  9.78044E+12  870 pages   \n",
       "2                    50th Anniversary   Paperback  9.78006E+12  324 pages   \n",
       "3  Modern Library Classics, USA / CAN   Paperback  9.78068E+12  279 pages   \n",
       "4                                 NaN   Paperback  9.78032E+12  498 pages   \n",
       "\n",
       "   book_rating  book_rating_count  book_review_count  \\\n",
       "0         4.33            5519135             160706   \n",
       "1         4.48            2041594              33264   \n",
       "2         4.27            3745197              79450   \n",
       "3         4.25            2453620              54322   \n",
       "4         3.58            4281268              97991   \n",
       "\n",
       "                                  book_title  \\\n",
       "0                           The Hunger Games   \n",
       "1  Harry Potter and the Order of the Phoenix   \n",
       "2                      To Kill a Mockingbird   \n",
       "3                        Pride and Prejudice   \n",
       "4                                   Twilight   \n",
       "\n",
       "                                              genres  \\\n",
       "0  Young Adult|Fiction|Science Fiction|Dystopia|F...   \n",
       "1                        Fantasy|Young Adult|Fiction   \n",
       "2  Classics|Fiction|Historical|Historical Fiction...   \n",
       "3                           Classics|Fiction|Romance   \n",
       "4  Young Adult|Fantasy|Romance|Paranormal|Vampire...   \n",
       "\n",
       "                                           image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603l...  \n",
       "1  https://images.gr-assets.com/books/1255614970l...  \n",
       "2  https://images.gr-assets.com/books/1361975680l...  \n",
       "3  https://images.gr-assets.com/books/1320399351l...  \n",
       "4  https://images.gr-assets.com/books/1361039443l...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the raw data\n",
    "\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54301, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of the dataframe\n",
    "\n",
    "books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only columns that are relevant to the current analysis\n",
    "\n",
    "books = books[[\"book_title\", \"book_authors\", \"book_desc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "\n",
    "books.columns = [\"title\", \"author\", \"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the first author for any book - a crude method, but focuses on the probable main author\n",
    "\n",
    "books.loc[:, \"author\"] = books[\"author\"].str.split(\"|\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>Winning will make you famous. Losing means cer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>«È cosa ormai risaputa che a uno scapolo in po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>About three things I was absolutely positive.F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title           author  \\\n",
       "0                           The Hunger Games  Suzanne Collins   \n",
       "1  Harry Potter and the Order of the Phoenix     J.K. Rowling   \n",
       "2                      To Kill a Mockingbird       Harper Lee   \n",
       "3                        Pride and Prejudice      Jane Austen   \n",
       "4                                   Twilight  Stephenie Meyer   \n",
       "\n",
       "                                         description  \n",
       "0  Winning will make you famous. Losing means cer...  \n",
       "1  There is a door at the end of a silent corrido...  \n",
       "2  The unforgettable novel of a childhood in a sl...  \n",
       "3  «È cosa ormai risaputa che a uno scapolo in po...  \n",
       "4  About three things I was absolutely positive.F...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data\n",
    "\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "Stephen King          180\n",
       "Cassandra Clare       118\n",
       "Anonymous             115\n",
       "Nora Roberts          107\n",
       "Terry Pratchett       106\n",
       "Agatha Christie       105\n",
       "James Patterson        97\n",
       "Neil Gaiman            89\n",
       "Rick Riordan           84\n",
       "George R.R. Martin     84\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the most popular authors\n",
    "\n",
    "books.groupby(\"author\").count() \\\n",
    "                       .sort_values(by=\"title\", ascending=False)[\"title\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high number of titles suggests that some authors have duplicate titles - perhaps different editions or translations. The next step is to detect and remove those duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace any missing descriptions with an empty string\n",
    "\n",
    "books.loc[:, \"description\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# Select just the descriptions\n",
    "\n",
    "descriptions = books[\"description\"]\n",
    "\n",
    "# Apply processing to the descriptions to simplify and remove awkward characters\n",
    "\n",
    "descriptions = descriptions.str.lower() \\\n",
    "                           .str.replace(\"[^a-z ]\", \" \") \\\n",
    "                           .str.replace(r\"\\s+\", \" \")\n",
    "\n",
    "# Overwrite the original descriptions\n",
    "\n",
    "books.loc[:, \"description\"] = descriptions\n",
    "\n",
    "# Drop any rows with missing or very short descriptions (<=100 characters)\n",
    "\n",
    "books = books[books[\"description\"].apply(len) > 100]\n",
    "\n",
    "# Drop any rows with duplicate descriptions\n",
    "\n",
    "books = books.drop_duplicates(subset=[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the language of each description; this code takes a while to run\n",
    "\n",
    "books.loc[:, \"language\"] = books[\"description\"].apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, drop all non-English books\n",
    "\n",
    "books = books[books[\"language\"] == \"en\"]\n",
    "\n",
    "# Drop the now-superfluous language column\n",
    "\n",
    "books.drop(\"language\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>winning will make you famous losing means cert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>there is a door at the end of a silent corrido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>the unforgettable novel of a childhood in a sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>about three things i was absolutely positive f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Book Thief</td>\n",
       "      <td>Markus Zusak</td>\n",
       "      <td>trying to make sense of the horrors of world w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title           author  \\\n",
       "0                           The Hunger Games  Suzanne Collins   \n",
       "1  Harry Potter and the Order of the Phoenix     J.K. Rowling   \n",
       "2                      To Kill a Mockingbird       Harper Lee   \n",
       "4                                   Twilight  Stephenie Meyer   \n",
       "5                             The Book Thief     Markus Zusak   \n",
       "\n",
       "                                         description  \n",
       "0  winning will make you famous losing means cert...  \n",
       "1  there is a door at the end of a silent corrido...  \n",
       "2  the unforgettable novel of a childhood in a sl...  \n",
       "4  about three things i was absolutely positive f...  \n",
       "5  trying to make sense of the horrors of world w...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop everything from each title after a breaking point (dash, bracket, colon, slash)\n",
    "# This is a somewhat crude measure that will deal with omnibuses and different edition titles\n",
    "\n",
    "books.loc[:, \"title\"] = books[\"title\"].apply(lambda title: re.split(\":|\\(| - |/\", title)[0].strip())\n",
    "\n",
    "# Drop everything with a title that implies multiple works in one book\n",
    "\n",
    "books = books[~books[\"title\"].str.lower().str.contains(\"omnibus|box set|boxed set|compilation|collection\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be many books with slight differences in titles, or with titles in another language although the description is in English. We need to remove as many of those as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another column for matching titles, in lowercase\n",
    "\n",
    "books[\"clean_title\"] = books[\"title\"].str.lower().str.strip()\n",
    "\n",
    "# Remove punctuation, etc. from the title\n",
    "\n",
    "books.loc[:, \"clean_title\"] = books[\"clean_title\"].str.replace(\"[^a-z ]\", \" \") \\\n",
    "                                                  .str.replace(r\"\\s+\", \" \")\n",
    "\n",
    "# Drop rows with an empty/very short clean_title column\n",
    "\n",
    "books.loc[:, \"clean_title\"] = books[\"clean_title\"].fillna(\"\")\n",
    "\n",
    "books = books[books[\"clean_title\"].apply(len) >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all books with duplicate titles\n",
    "\n",
    "books = books.drop_duplicates(subset=[\"title\"])\n",
    "\n",
    "books = books.drop_duplicates(subset=[\"clean_title\"])\n",
    "\n",
    "# Drop now-superfluous columns\n",
    "\n",
    "books = books.drop(columns=[\"clean_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37514, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the new shape of the dataframe\n",
    "\n",
    "books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "James Patterson    77\n",
       "Nora Roberts       75\n",
       "Stephen King       72\n",
       "Anonymous          69\n",
       "Agatha Christie    68\n",
       "Terry Pratchett    61\n",
       "Francine Pascal    60\n",
       "Carolyn Keene      56\n",
       "J.D. Robb          52\n",
       "Meg Cabot          51\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the most popular authors\n",
    "\n",
    "books.groupby(\"author\").count() \\\n",
    "                       .sort_values(by=\"title\", ascending=False)[\"title\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now got a much more reasonable series of numbers for most popular authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 37514 different books by 17091 different authors.\n"
     ]
    }
   ],
   "source": [
    "# Output overview figures\n",
    "\n",
    "print(f\"The dataset contains {books.shape[0]} different books by {books['author'].nunique()} different authors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index to be sequential again\n",
    "\n",
    "books.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>winning will make you famous losing means cert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>there is a door at the end of a silent corrido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>the unforgettable novel of a childhood in a sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>about three things i was absolutely positive f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Book Thief</td>\n",
       "      <td>Markus Zusak</td>\n",
       "      <td>trying to make sense of the horrors of world w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title           author  \\\n",
       "0                           The Hunger Games  Suzanne Collins   \n",
       "1  Harry Potter and the Order of the Phoenix     J.K. Rowling   \n",
       "2                      To Kill a Mockingbird       Harper Lee   \n",
       "3                                   Twilight  Stephenie Meyer   \n",
       "4                             The Book Thief     Markus Zusak   \n",
       "\n",
       "                                         description  \n",
       "0  winning will make you famous losing means cert...  \n",
       "1  there is a door at the end of a silent corrido...  \n",
       "2  the unforgettable novel of a childhood in a sl...  \n",
       "3  about three things i was absolutely positive f...  \n",
       "4  trying to make sense of the horrors of world w...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the data\n",
    "\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the cleaned data\n",
    "\n",
    "The above processing stages take a lot of time, so to save time in future, we'll write the dataframe to a file now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv(\"books.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in from a file\n",
    "\n",
    "books = pd.read_csv(\"books.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>Saving Grace</td>\n",
       "      <td>Christine Zolendz</td>\n",
       "      <td>after spending over years being a lost soul lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35147</th>\n",
       "      <td>Interlude in Death</td>\n",
       "      <td>J.D. Robb</td>\n",
       "      <td>in early spring of lieutenant eve dallas is ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11147</th>\n",
       "      <td>The End of the World</td>\n",
       "      <td>Derek Landy</td>\n",
       "      <td>skulduggery and valkyrie are back in an exclus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17161</th>\n",
       "      <td>Rua</td>\n",
       "      <td>Miranda Kavi</td>\n",
       "      <td>a girl with an unknown destiny a boy from a hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12479</th>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Stacy Schiff</td>\n",
       "      <td>the pulitzer prize winning biographer brings t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23210</th>\n",
       "      <td>Nature</td>\n",
       "      <td>Ralph Waldo Emerson</td>\n",
       "      <td>together in one volume ralph waldo emerson s n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5923</th>\n",
       "      <td>Freedom or Death</td>\n",
       "      <td>Nikos Kazantzakis</td>\n",
       "      <td>freedom or death by nikos kazantzakis is a nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24672</th>\n",
       "      <td>Missionary Patriarch</td>\n",
       "      <td>John G. Paton</td>\n",
       "      <td>john g paton s accounts of evangelism among th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12841</th>\n",
       "      <td>Angel Sister</td>\n",
       "      <td>Ann H. Gabhart</td>\n",
       "      <td>it is and kate merritt the middle child of vic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34277</th>\n",
       "      <td>Come Monday</td>\n",
       "      <td>Mari Carr</td>\n",
       "      <td>come monday mari carr wild irish book one mond...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title               author  \\\n",
       "6062           Saving Grace    Christine Zolendz   \n",
       "35147    Interlude in Death            J.D. Robb   \n",
       "11147  The End of the World          Derek Landy   \n",
       "17161                   Rua         Miranda Kavi   \n",
       "12479             Cleopatra         Stacy Schiff   \n",
       "23210                Nature  Ralph Waldo Emerson   \n",
       "5923       Freedom or Death    Nikos Kazantzakis   \n",
       "24672  Missionary Patriarch        John G. Paton   \n",
       "12841          Angel Sister       Ann H. Gabhart   \n",
       "34277           Come Monday            Mari Carr   \n",
       "\n",
       "                                             description  \n",
       "6062   after spending over years being a lost soul lo...  \n",
       "35147  in early spring of lieutenant eve dallas is ca...  \n",
       "11147  skulduggery and valkyrie are back in an exclus...  \n",
       "17161  a girl with an unknown destiny a boy from a hi...  \n",
       "12479  the pulitzer prize winning biographer brings t...  \n",
       "23210  together in one volume ralph waldo emerson s n...  \n",
       "5923   freedom or death by nikos kazantzakis is a nov...  \n",
       "24672  john g paton s accounts of evangelism among th...  \n",
       "12841  it is and kate merritt the middle child of vic...  \n",
       "34277  come monday mari carr wild irish book one mond...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "Although the data is now cleaned, it still needs some processing to make sure that analysis of the descriptions is meaningful. This process will focus on reducing the dimensionality of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select just the descriptions\n",
    "\n",
    "descriptions = books[\"description\"]\n",
    "\n",
    "# Split words into tokens\n",
    "\n",
    "descriptions = descriptions.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to *lemmatize* the descriptions - to reduce each word to its dictionary form. This reduces dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map tags to ones that the lemmatiser will understand.\n",
    "\n",
    "tag_map = defaultdict(lambda : \"n\")  # by default, assume nouns\n",
    "tag_map['J'] = \"a\"  # adjectives\n",
    "tag_map['V'] = \"v\"  # verbs\n",
    "tag_map['R'] = \"r\"  # adverbs\n",
    "\n",
    "# Create a function to get the pos tags for a set of tokens, and return the tokens in a way a\n",
    "# lemmatizer can interpret\n",
    "def get_wordnet_tags(tokens):\n",
    "    \"\"\"Returns WordNet pos_tags for a set of tokens\"\"\"\n",
    "    \n",
    "    # Tag tokens with pos_tagger\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    \n",
    "    # Convert each tag to a version wordnet can understand\n",
    "    tagged_tokens = [(token[0], tag_map[token[1][0]]) for token in tagged_tokens]\n",
    "    \n",
    "    return tagged_tokens\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Create a lemmatizing object\n",
    "\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag each token in each description\n",
    "\n",
    "descriptions = descriptions.apply(get_wordnet_tags)\n",
    "\n",
    "# Lemmatize the sets of tokens; this code takes a while to run\n",
    "\n",
    "descriptions = descriptions.apply(lambda tokens: [lemma.lemmatize(word=token[0],\n",
    "                                                                  pos=token[1])\n",
    "                                                  for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next stage is to reduce the number of terms by removing small functional words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of stopwords\n",
    "\n",
    "stops = stopwords.words(\"english\")\n",
    "\n",
    "# Filter out all stopwords and words less than 3 letters long from the descriptions.\n",
    "\n",
    "descriptions = descriptions.apply(lambda tokens: [word for word in tokens\n",
    "                                                  if word not in stops\n",
    "                                                  and len(word) > 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - what are the most frequent words in descriptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the descriptions together into a list of lists\n",
    "\n",
    "tokens = descriptions.to_list()\n",
    "\n",
    "# Flatten the lists\n",
    "\n",
    "tokens = flatten(tokens)\n",
    "\n",
    "# Count each unique word\n",
    "\n",
    "token_counts = Counter(tokens)\n",
    "\n",
    "# Convert the counter dict into a sortable series\n",
    "\n",
    "token_counts = pd.Series(token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the top ten terms\n",
    "\n",
    "token_counts.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "token_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the top twenty terms\n",
    "\n",
    "top_twenty = token_counts.head(20)\n",
    "\n",
    "# Plot the top twenty as a bar chart\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.xticks(fontsize=14, rotation=45)\n",
    "plt.ylabel(\"Frequency\", fontsize=16, labelpad=10)\n",
    "plt.xlabel(\"Word\", fontsize=16, labelpad=10)\n",
    "plt.title(\"Top twenty words in book descriptions\",\n",
    "          fontsize=18, pad=10)\n",
    "\n",
    "sns.barplot(x=top_twenty.index, y=top_twenty,\n",
    "            palette=\"winter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "In order to identify similar books, we'll use [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) as a way to determine key terms in each description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the tokens back into strings\n",
    "\n",
    "descriptions = descriptions.apply(lambda text: \" \".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tfidf vectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, min_df=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a document-term matrix using the vectorizer\n",
    "\n",
    "description_dtm = tfidf_vectorizer.fit_transform(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the dtm\n",
    "\n",
    "description_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: can TF-IDF vectors effectively distinguish between different documents?\n",
    "\n",
    "A recommendation engine will fail - but look like it's succeeding - if it can't effectively distinguish between different books. It will find similarites, but they won't be meaningful, because it won't have picked up on dissimilarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DTM to a dataframe\n",
    "\n",
    "vectors = pd.DataFrame(columns=tfidf_vectorizer.get_feature_names(),\n",
    "                       data=description_dtm.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the rows with at least one duplicate\n",
    "\n",
    "duplicates = vectors[vectors.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match up the duplicates by sorting based on all columns\n",
    "\n",
    "duplicates = duplicates.sort_values(by=list(duplicates.columns)).index\n",
    "\n",
    "# Select the duplicated rows as a new dataframe\n",
    "\n",
    "duplicate_df = books.iloc[list(duplicates)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 24 different books by 16 different authors.\n",
      "There are 24 distinct descriptions.\n"
     ]
    }
   ],
   "source": [
    "# Output key figures\n",
    "\n",
    "print(f\"The dataset contains {duplicate_df.shape[0]} different books by {duplicate_df['author'].nunique()} different authors.\")\n",
    "print(f\"There are {duplicate_df['description'].nunique()} distinct descriptions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30060</th>\n",
       "      <td>Broca's Brain</td>\n",
       "      <td>Carl Sagan</td>\n",
       "      <td>carl sagan writer scientist returns from the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34213</th>\n",
       "      <td>O Cérebro de Broca</td>\n",
       "      <td>Carl Sagan</td>\n",
       "      <td>pre isbncarl sagan writer and scientist return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>The Taming of the Shrew</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>the arden shakespeare is the established editi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16677</th>\n",
       "      <td>Timon of Athens</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>the arden shakespeare is the established editi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26188</th>\n",
       "      <td>All The Rivers Run</td>\n",
       "      <td>Nancy Cato</td>\n",
       "      <td>free delivery if order value from the seller i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34744</th>\n",
       "      <td>Michael Morpurgo Escape from Shangri-La</td>\n",
       "      <td>Michael Morpurgo</td>\n",
       "      <td>free shipping if order value from the seller i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16656</th>\n",
       "      <td>In the Land of the Living Dead</td>\n",
       "      <td>Prentiss Tucker</td>\n",
       "      <td>many of the earliest books particularly those ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20824</th>\n",
       "      <td>Der Teufel In Frankreich. Erlebnisse</td>\n",
       "      <td>Lion Feuchtwanger</td>\n",
       "      <td>many of the earliest books particularly those ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621</th>\n",
       "      <td>Beneath the Wheel</td>\n",
       "      <td>Hermann Hesse</td>\n",
       "      <td>in hermann hesse s beneath the wheel or the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26146</th>\n",
       "      <td>The Prodigy</td>\n",
       "      <td>Hermann Hesse</td>\n",
       "      <td>in hermann hesse s beneath the wheel or the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10951</th>\n",
       "      <td>The Silence of Bonaventure Arrow</td>\n",
       "      <td>Rita Leganski</td>\n",
       "      <td>conceived in love and possibility bonaventure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17144</th>\n",
       "      <td>The Silence of Bonadventure Arrow</td>\n",
       "      <td>Rita Leganski</td>\n",
       "      <td>from harper collins conceived in love and poss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>If This Is a Man</td>\n",
       "      <td>Primo Levi</td>\n",
       "      <td>with the moral stamina and intellectual poise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22039</th>\n",
       "      <td>Se questo è un uomo</td>\n",
       "      <td>Primo Levi</td>\n",
       "      <td>testimonianza sconvolgente sull inferno dei la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23320</th>\n",
       "      <td>The Price of Liberty</td>\n",
       "      <td>Wayne Whipple</td>\n",
       "      <td>this scarce antiquarian book is a selection fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24731</th>\n",
       "      <td>Ancient Mariner; Kubla Khan and Christabel</td>\n",
       "      <td>Samuel Taylor Coleridge</td>\n",
       "      <td>this scarce antiquarian book is a selection fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27214</th>\n",
       "      <td>The Aristocats</td>\n",
       "      <td>Walt Disney Company</td>\n",
       "      <td>relive walt disney s th full length animated f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34578</th>\n",
       "      <td>Disney's the Lion King</td>\n",
       "      <td>Don Ferguson</td>\n",
       "      <td>relive walt disney s nd full length animated f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28690</th>\n",
       "      <td>I Can Cook</td>\n",
       "      <td>Marika Germanis</td>\n",
       "      <td>a children s simple puddings and dessert cook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29356</th>\n",
       "      <td>I Can Cook \"Pastry\"</td>\n",
       "      <td>Marika Germanis</td>\n",
       "      <td>a children s simple pastry cook book with simp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37170</th>\n",
       "      <td>Learn Spanish</td>\n",
       "      <td>Innovative Language</td>\n",
       "      <td>master spanish with learn spanish word power t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37408</th>\n",
       "      <td>Learn Dutch</td>\n",
       "      <td>Innovative Language</td>\n",
       "      <td>master dutch with learn dutch word power this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30798</th>\n",
       "      <td>Oh, James!</td>\n",
       "      <td>Mark Tonra</td>\n",
       "      <td>the little kid with the giant personality is b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>Hey James!</td>\n",
       "      <td>Mark Tonra</td>\n",
       "      <td>the little kid with the giant personality is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title                   author  \\\n",
       "30060                               Broca's Brain               Carl Sagan   \n",
       "34213                          O Cérebro de Broca               Carl Sagan   \n",
       "850                       The Taming of the Shrew      William Shakespeare   \n",
       "16677                             Timon of Athens      William Shakespeare   \n",
       "26188                          All The Rivers Run               Nancy Cato   \n",
       "34744     Michael Morpurgo Escape from Shangri-La         Michael Morpurgo   \n",
       "16656              In the Land of the Living Dead          Prentiss Tucker   \n",
       "20824        Der Teufel In Frankreich. Erlebnisse        Lion Feuchtwanger   \n",
       "4621                            Beneath the Wheel            Hermann Hesse   \n",
       "26146                                 The Prodigy            Hermann Hesse   \n",
       "10951            The Silence of Bonaventure Arrow            Rita Leganski   \n",
       "17144           The Silence of Bonadventure Arrow            Rita Leganski   \n",
       "8670                             If This Is a Man               Primo Levi   \n",
       "22039                         Se questo è un uomo               Primo Levi   \n",
       "23320                        The Price of Liberty            Wayne Whipple   \n",
       "24731  Ancient Mariner; Kubla Khan and Christabel  Samuel Taylor Coleridge   \n",
       "27214                              The Aristocats      Walt Disney Company   \n",
       "34578                      Disney's the Lion King             Don Ferguson   \n",
       "28690                                  I Can Cook          Marika Germanis   \n",
       "29356                         I Can Cook \"Pastry\"          Marika Germanis   \n",
       "37170                               Learn Spanish      Innovative Language   \n",
       "37408                                 Learn Dutch      Innovative Language   \n",
       "30798                                  Oh, James!               Mark Tonra   \n",
       "33553                                  Hey James!               Mark Tonra   \n",
       "\n",
       "                                             description  \n",
       "30060  carl sagan writer scientist returns from the f...  \n",
       "34213  pre isbncarl sagan writer and scientist return...  \n",
       "850    the arden shakespeare is the established editi...  \n",
       "16677  the arden shakespeare is the established editi...  \n",
       "26188  free delivery if order value from the seller i...  \n",
       "34744  free shipping if order value from the seller i...  \n",
       "16656  many of the earliest books particularly those ...  \n",
       "20824  many of the earliest books particularly those ...  \n",
       "4621   in hermann hesse s beneath the wheel or the pr...  \n",
       "26146  in hermann hesse s beneath the wheel or the pr...  \n",
       "10951  conceived in love and possibility bonaventure ...  \n",
       "17144  from harper collins conceived in love and poss...  \n",
       "8670    with the moral stamina and intellectual poise...  \n",
       "22039  testimonianza sconvolgente sull inferno dei la...  \n",
       "23320  this scarce antiquarian book is a selection fr...  \n",
       "24731  this scarce antiquarian book is a selection fr...  \n",
       "27214  relive walt disney s th full length animated f...  \n",
       "34578  relive walt disney s nd full length animated f...  \n",
       "28690  a children s simple puddings and dessert cook ...  \n",
       "29356  a children s simple pastry cook book with simp...  \n",
       "37170  master spanish with learn spanish word power t...  \n",
       "37408  master dutch with learn dutch word power this ...  \n",
       "30798  the little kid with the giant personality is b...  \n",
       "33553  the little kid with the giant personality is b...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final analysis, only 24 duplicates were found: 24 books with TF-IDF vectors that were identical to another book's description. These books all had extremely similar descriptions, so it is not surprising that the vectors were the same. The problem here is in the data, not the metrics: some books have non-specifc descriptions.\n",
    "\n",
    "Overall, TF-IDF sufficiently differentiates between different books, with only very minor confusion. This means that is a viable choice for building the recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate similarities for a document\n",
    "\n",
    "Once we have the document-term matrix of TF-IDF scores, we can calculate the similarity between books by looking for similarities in their TF-IDF vectors. To do this, we need the `cosine_similarity` score.\n",
    "\n",
    "As a test description, we'll use [Steve Alten's *Meg*](https://www.goodreads.com/book/show/105744.Meg) to check our recommendations. One edition of *Meg* is already in the dataset, so we should get at least one result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that processes a text description into the same format as the provided descriptions\n",
    "\n",
    "def convert_text_to_vector(text):\n",
    "    \"\"\"Converts a text string into a TFIDF vector\n",
    "    \n",
    "       Input:\n",
    "           - text (str): a book description\n",
    "       Output:\n",
    "           - vector \n",
    "    \"\"\"\n",
    "    # Clean text\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^a-z ]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    # Lemmatize and remove stopwords\n",
    "    text = text.split(\" \")\n",
    "    text = get_wordnet_tags(text)\n",
    "    text = [lemma.lemmatize(word=word[0], pos=word[1]) for word in text]\n",
    "    text = [word for word in text if word not in stops and len(word) > 3]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # Convert the description to a TF-IDF vector\n",
    "    vector = tfidf_vectorizer.transform([text])\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_wordnet_tags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5b5f8ff47c8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_text_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cats\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-6248eb5a3012>\u001b[0m in \u001b[0;36mconvert_text_to_vector\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Lemmatize and remove stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_wordnet_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlemma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstops\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_wordnet_tags' is not defined"
     ]
    }
   ],
   "source": [
    "type(convert_text_to_vector(\"cats\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example description string \n",
    "\n",
    "test_description = \"\"\"On a top-secret dive into the Pacific Ocean's deepest canyon,\n",
    "                      Jonas Taylor found himself face-to-face with the largest and\n",
    "                      most ferocious predator in the history of the animal kingdom.\n",
    "                      The sole survivor of the mission, Taylor is haunted by what\n",
    "                      he's sure he saw but still can't prove exists - Carcharodon\n",
    "                      megalodon, the massive mother of the great white shark. The\n",
    "                      average prehistoric Meg weighs in at twenty tons and could\n",
    "                      tear apart a Tyrannosaurus rex in seconds. Taylor spends years\n",
    "                      theorizing, lecturing, and writing about the possibility that\n",
    "                      Meg still feeds at the deepest levels of the sea. But it takes\n",
    "                      an old friend in need to get him to return to the water, and a\n",
    "                      hotshot female submarine pilot to dare him back into a high-tech\n",
    "                      miniature sub. Diving deeper than he ever has before, Taylor will\n",
    "                      face terror like he's never imagined. MEG is about to surface.\n",
    "                      When she does, nothing and no one is going to be safe, and Jonas\n",
    "                      must face his greatest fear once again.\"\"\"\n",
    "\n",
    "# Convert the test description to a vector \n",
    "\n",
    "query_vector = convert_text_to_vector(test_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1261 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 45 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cosine similarity to find the most similar vectors to the test\n",
    "\n",
    "similarities = cosine_similarity(query_vector, description_dtm).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - can we make reasonable recommendations?\n",
    "\n",
    "Now that we can calculate similarities between book descriptions, we can simply match those similarities back to the books and return the authors & titles of the books with the highest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17147</th>\n",
       "      <td>Steve Alten</td>\n",
       "      <td>Meg</td>\n",
       "      <td>0.960885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25681</th>\n",
       "      <td>Maud Hart Lovelace</td>\n",
       "      <td>Emily of Deep Valley</td>\n",
       "      <td>0.306204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>Judith Reeves-Stevens</td>\n",
       "      <td>The Fall of Terok Nor</td>\n",
       "      <td>0.263083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>Alyson Noel</td>\n",
       "      <td>Night Star</td>\n",
       "      <td>0.261695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22891</th>\n",
       "      <td>R.W. Ridley</td>\n",
       "      <td>The Gore</td>\n",
       "      <td>0.260723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8533</th>\n",
       "      <td>Dani Pettrey</td>\n",
       "      <td>Submerged</td>\n",
       "      <td>0.251148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10868</th>\n",
       "      <td>Julia Golding</td>\n",
       "      <td>Secret of the Sirens</td>\n",
       "      <td>0.248845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>Helen Dunmore</td>\n",
       "      <td>The Deep</td>\n",
       "      <td>0.247202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26120</th>\n",
       "      <td>Chris Heimerdinger</td>\n",
       "      <td>Tower of Thunder</td>\n",
       "      <td>0.237470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8414</th>\n",
       "      <td>Maud Hart Lovelace</td>\n",
       "      <td>Carney's House Party</td>\n",
       "      <td>0.235357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      author                  title  similarity\n",
       "17147            Steve Alten                    Meg    0.960885\n",
       "25681     Maud Hart Lovelace   Emily of Deep Valley    0.306204\n",
       "21612  Judith Reeves-Stevens  The Fall of Terok Nor    0.263083\n",
       "2445             Alyson Noel             Night Star    0.261695\n",
       "22891            R.W. Ridley               The Gore    0.260723\n",
       "8533            Dani Pettrey              Submerged    0.251148\n",
       "10868          Julia Golding   Secret of the Sirens    0.248845\n",
       "5572           Helen Dunmore               The Deep    0.247202\n",
       "26120     Chris Heimerdinger       Tower of Thunder    0.237470\n",
       "8414      Maud Hart Lovelace   Carney's House Party    0.235357"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a copy of books to match scores against\n",
    "\n",
    "recommendation_df = books[[\"author\", \"title\"]].copy()\n",
    "\n",
    "# Add the similarity scores as another column\n",
    "\n",
    "recommendation_df[\"similarity\"] = similarities\n",
    "\n",
    "# Sort the dataframe by similarity\n",
    "\n",
    "recommendation_df.sort_values(by=\"similarity\", ascending=False, inplace=True)\n",
    "\n",
    "# Output the top ten recommendations\n",
    "\n",
    "recommendation_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! The most similar book to *Meg* is *Meg*, which shows that our recommender is working. The other books suggested are generally reasonable ones; for example, *Submerged* by Dani Pettrey is also about horror in the depths.\n",
    "\n",
    "*Emily of Deep Valley* is not particularly similar in tone or theme, but both books have the word \"deep\" frequently in their descriptions. This shows one weakness of TF-IDF; it picks up on relative word importance, but struggles with words being used in different contexts.\n",
    "\n",
    "We have successfully built a recommendation system, though it does still have flaws. Potential refinements would be\n",
    "\n",
    "1. Consider genre, and only recommend books in a similar category, even if highly similar\n",
    "2. Remove named entities as a processing step; character names are frequent in descriptions but don't suggest anything about themes etc.\n",
    "3. Use longer text - descriptions might not have much discerning power compared to reviews or actual excerpts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation tool\n",
    "\n",
    "The next cell is an all-in-one recommendation engine: enter a description in the provided text box, and see a list of recommended other books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a book description: The war is over, and army priest Tomas Piety heads home with Sergeant Bloody Anne at his side. But things have changed while he was away: his crime empire has been stolen and the people of Ellinburg--his people--have run out of food and hope and places to hide. Tomas sets out to reclaim what was his with help from Anne, his brother, Jochan, and his new gang: the Pious Men. But when he finds himself dragged into a web of political intrigue once again, everything gets more complicated.  As the Pious Men fight shadowy foreign infiltrators in the back-street taverns, brothels, and gambling dens of Tomas's old life, it becomes clear: The war is only just beginning.\n",
      "--------------------------------------------------------------\n",
      "Based on that description, your top 5 recommendations are\n",
      "1. Born, by A.E. Watson\n",
      "2. Treasure, by S.  Smith\n",
      "3. There's No Place Like Here, by Cecelia Ahern\n",
      "4. Reaper's Gale, by Steven Erikson\n",
      "5. Tokyo Crazy Paradise, Vol. 1, by Yoshiki Nakamura\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user for a description\n",
    "\n",
    "book_description = input(\"Enter a book description: \")\n",
    "\n",
    "# Process the description\n",
    "\n",
    "query_vector = convert_text_to_vector(book_description)\n",
    "\n",
    "# Calculate similarities\n",
    "\n",
    "similarities = cosine_similarity(query_vector, description_dtm).flatten()\n",
    "\n",
    "# Take a copy of books to match scores against\n",
    "\n",
    "recommendation_df = books[[\"author\", \"title\"]].copy()\n",
    "\n",
    "# Add the similarity scores as another column\n",
    "\n",
    "recommendation_df[\"similarity\"] = similarities\n",
    "\n",
    "# Sort the dataframe by similarity\n",
    "\n",
    "recommendations = recommendation_df.sort_values(by=\"similarity\",\n",
    "                                                ascending=False).reset_index(drop=True).head(5)\n",
    "\n",
    "# Output formatted recommendations\n",
    "\n",
    "print(\"--------------------------------------------------------------\\nBased on that description, your top 5 recommendations are\")\n",
    "for book in recommendations.iterrows():\n",
    "    print(f\"{book[0] + 1}. {book[1]['title']}, by {book[1]['author']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
